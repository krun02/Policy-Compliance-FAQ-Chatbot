# Policy-Compliance-FAQ-Chatbot (RAG using Ollama + Streamlit)
This project is an interactive chatbot that answers questions related to **SOC 2**, **HIPAA**, and **NIST** policies by leveraging **Retrieval-Augmented Generation (RAG)**. It uses **LangChain**, **HuggingFace Embeddings**, **FAISS** for vector search, and **Ollama (Mistral model)** as the backend LLM. The chatbot is designed for **offline use**, making it suitable for internal audits, compliance reviews, and GRC (Governance, Risk & Compliance) support without internet dependency.

## ğŸš€ Features

- âœ… Simple **Streamlit-based GUI**
- âœ… Loads local `.txt` policy documents and answers questions contextually
- âœ… Uses **FAISS** for fast document similarity search
- âœ… Embeds policy documents with **MiniLM-L6** embeddings
- âœ… Powered by **Ollama** running LLM like `mistral` or `llama3`
- âœ… Supports **SOC 2**, **HIPAA**, and **NIST** queries
- âœ… Completely **offline-compatible** (no OpenAI or external API usage)

ğŸ’¡ What It Can Do
Ask questions like:
â€œWhat is HIPAA's policy on data retention?â€
â€œWhat does SOC 2 say about access control?â€

Gives answers based on your documents

Runs completely offline using Ollama (local AI model)

Simple chat interface built with Streamlit

## ğŸ§  How It Works

1. **Document Ingestion**: Loads `.txt` policy files from the `docs/` folder.
2. **Chunking**: Splits documents into small overlapping text chunks using LangChain's `RecursiveCharacterTextSplitter`.
3. **Embedding**: Converts each chunk into dense vectors using `all-MiniLM-L6-v2` from HuggingFace.
4. **Indexing**: Stores these vectors into a **FAISS** vector database for efficient retrieval.
5. **Query Handling**:
   - User types a question via GUI.
   - Relevant chunks are retrieved using vector similarity.
   - A response is generated by an **Ollama** LLM model (e.g., Mistral).
6. **Display**: Response is shown in a friendly chatbot interface using Streamlit.

## ğŸ› ï¸ Prerequisites

- Python 3.9 or higher
- Ollama installed (for running the LLM locally)
  - Get it here: https://ollama.com
- HuggingFace and LangChain libraries

---
ğŸ™Œ Acknowledgements

LangChain

Ollama

HuggingFace Transformers

FAISS
  
## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/policy-faq-bot.git
cd policy-faq-bot

# Create virtual environment (optional)
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

---
